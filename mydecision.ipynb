{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we don't like warnings\n",
    "# you can comment the following 2 lines if you'd like to\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV, SGDClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import validation_curve, learning_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "data = pd.read_csv('train.csv',\n",
    "                   header=None, names = range(30))\n",
    "test = pd.read_csv('test.csv',\n",
    "                   header=None, names = range(30))\n",
    "# getting some info about dataframe\n",
    "y = pd.read_csv('train-target.csv',\n",
    "                   header=None, names=['a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, Xtest = data.values, y.values, test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X, y, Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-cdb40c79a5db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mplot_learning_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdegree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-cdb40c79a5db>\u001b[0m in \u001b[0;36mplot_learning_curve\u001b[0;34m(degree, alpha)\u001b[0m\n\u001b[1;32m     17\u001b[0m                            ('sgd_logit', SGDClassifier(n_jobs=-1, random_state=17, alpha=alpha, max_iter=5))])\n\u001b[1;32m     18\u001b[0m     N_train, val_train, val_test = learning_curve(logit_pipe,\n\u001b[0;32m---> 19\u001b[0;31m                                                   \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_sizes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m                                                   scoring='roc_auc')\n\u001b[1;32m     21\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m18\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "logit_pipe = Pipeline([('poly', PolynomialFeatures(degree=2)), \n",
    "                       ('logit', LogisticRegression(solver='lbfgs' ))])\n",
    "\n",
    "def plot_with_err(x, data, **kwargs):\n",
    "    mu, std = data.mean(1), data.std(1)\n",
    "    lines = plt.plot(x, mu, '-', **kwargs)\n",
    "    plt.fill_between(x, mu - std, mu + std, edgecolor='none',\n",
    "                     facecolor=lines[0].get_color(), alpha=0.2)\n",
    "\n",
    "\n",
    "def plot_learning_curve(degree=2, alpha=0.01):\n",
    "    train_sizes = np.linspace(0.05, 1, 20)\n",
    "    logit_pipe = Pipeline([('scaler', StandardScaler()), ('poly', PolynomialFeatures(degree=degree)), \n",
    "                           ('sgd_logit', SGDClassifier(n_jobs=-1, random_state=17, alpha=alpha, max_iter=5))])\n",
    "    N_train, val_train, val_test = learning_curve(logit_pipe,\n",
    "                                                  X, y, train_sizes=train_sizes, cv=5,\n",
    "                                                  scoring='roc_auc')\n",
    "    plt.figure(figsize=(18,10))\n",
    "    plot_with_err(N_train, val_train, label='training scores')\n",
    "    plot_with_err(N_train, val_test, label='validation scores')\n",
    "    plt.xlabel('Training Set Size'); plt.ylabel('AUC')\n",
    "    plt.legend()\n",
    "    plt.grid(True);\n",
    "\n",
    "plot_learning_curve(degree=2, alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0           1           2           3          4           5   \\\n",
      "0    -220.530530  -70.197440  119.035181   20.711737  -6.152986   52.225051   \n",
      "1      -8.536541   -8.305435 -117.828269  -28.588333  14.223240  -42.087807   \n",
      "2     126.229973  133.463504 -105.511797 -149.110267  -3.673355 -104.302244   \n",
      "3     369.571563   11.850181 -299.969407   29.371721  -3.457523 -115.901854   \n",
      "4     -99.563708  -85.166292  -73.363391  -35.357907   5.437025  -54.892519   \n",
      "...          ...         ...         ...         ...        ...         ...   \n",
      "9995  -91.804097   96.380816  -93.520627   85.282425  -7.178058  -58.349354   \n",
      "9996 -232.083597  -60.861115   45.472736    5.731012  -7.987843   39.012270   \n",
      "9997 -182.455289  -73.963540 -221.763797  -96.181654  -4.056096 -121.460703   \n",
      "9998 -268.344148   53.342079 -176.197832   45.925889   9.604607   59.329437   \n",
      "9999 -766.308667 -136.240073   26.516587 -153.518440  -6.515163   86.701607   \n",
      "\n",
      "              6           7           8           10  ...         20  \\\n",
      "0     -23.230903 -166.521871  -41.571463  271.292251  ...  16.936420   \n",
      "1     -45.538664   58.898976   27.749744  -97.233793  ...  57.027508   \n",
      "2       5.815395  100.838385  -46.240211  194.054804  ...   4.819849   \n",
      "3     159.134323 -149.741411 -108.847522 -215.802195  ...  80.930568   \n",
      "4      56.430532  -49.237377  -50.054608 -115.997344  ...  31.682235   \n",
      "...          ...         ...         ...         ...  ...        ...   \n",
      "9995  233.433179   67.060275  100.601251  -82.546051  ...  29.122841   \n",
      "9996  -78.622327   77.938740    8.091318  107.862166  ...  86.281234   \n",
      "9997  -33.409815 -136.962854  204.767129 -202.054583  ... -23.305907   \n",
      "9998   67.922422   81.571360  -85.361397 -394.669287  ... -69.562156   \n",
      "9999  155.733257  238.601187  -27.854601  193.788408  ...  32.248595   \n",
      "\n",
      "              21          22          23          24         25        26  \\\n",
      "0      46.543585  -80.962171 -146.652218   10.899085   4.370985  4.060272   \n",
      "1     121.304258   31.507396   88.282912   66.766185  -4.363974 -5.791376   \n",
      "2      88.905713   51.475105  -73.257358  108.947287   8.567240  0.116269   \n",
      "3    -166.476192  -73.882682  108.222355   19.573192  -2.242024  0.515601   \n",
      "4     209.163125  -22.847302  -62.067337   58.109167   2.862082  0.920341   \n",
      "...          ...         ...         ...         ...        ...       ...   \n",
      "9995  418.328185   35.687836  -13.778557   19.527466   1.860720 -0.928468   \n",
      "9996  -29.944248   39.432925   89.389986  -51.332647  -3.602386  0.323119   \n",
      "9997  102.332041  -67.763884  -50.665547  -41.240901   1.876399  0.719234   \n",
      "9998   44.399330   42.172405   32.269383   39.902889   2.205488  4.073904   \n",
      "9999   71.169494  121.583149   27.046068 -130.540017 -12.519139 -1.647082   \n",
      "\n",
      "              27          28          29  \n",
      "0      40.680890  -37.942655   33.838225  \n",
      "1     -32.101939  -52.255449   -4.826111  \n",
      "2    -117.205053 -107.835928  -93.990332  \n",
      "3     -25.218215  121.674228  -16.877368  \n",
      "4    -132.875142    3.492953  -15.799596  \n",
      "...          ...         ...         ...  \n",
      "9995  100.397658  -83.305311 -132.648400  \n",
      "9996   35.417264  -66.463502    5.783203  \n",
      "9997  -55.564211 -207.574071   86.333468  \n",
      "9998   -7.932393    2.626694   78.433097  \n",
      "9999  152.856744  -68.890937   56.441209  \n",
      "\n",
      "[10000 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "X = data.drop(9, axis=1)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000 1000\n",
      "Accuracy on training set: 0.828\n",
      "Accuracy on test set: 0.827\n",
      "AUC ROC:  0.8903051928028802\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "data = pd.read_csv('train.csv',\n",
    "                   header=None, names = range(30))\n",
    "test = pd.read_csv('test.csv',\n",
    "                   header=None, names = range(30))\n",
    "# getting some info about dataframe\n",
    "y = pd.read_csv('train-target.csv',\n",
    "                   header=None, names=['a'])\n",
    "\n",
    "X, y, Xtest = data.drop([9,15,16],axis=1).values, y.values, test.drop([9,15,16],axis=1).values\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "\n",
    "logit_pipe = Pipeline([('scaler', StandardScaler()), \n",
    "                           ('lr_logit', LogisticRegression())])\n",
    "\n",
    "clf = logit_pipe.fit(X_train,y_train)\n",
    "print(y_train.size, y_test.size)\n",
    "\n",
    "print(\"Accuracy on training set:\", \n",
    "      round(logit_pipe.score(X_train, y_train), 3))\n",
    "\n",
    "print(\"Accuracy on test set:\", \n",
    "      round(logit_pipe. score(X_test, y_test), 3))\n",
    "\n",
    "score = roc_auc_score(y_test, logit_pipe.predict_proba(X_test)[:,1])\n",
    "print(\"AUC ROC: \",score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualize_coefficients(classifier, feature_names, n_top_features=25):\n",
    "    # get coefficients with large absolute values \n",
    "    coef = classifier.coef_.ravel()\n",
    "    positive_coefficients = np.argsort(coef)[-n_top_features:]\n",
    "    negative_coefficients = np.argsort(coef)[:n_top_features]\n",
    "    interesting_coefficients = np.hstack([negative_coefficients, positive_coefficients])\n",
    "    # plot them\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    colors = [\"red\" if c < 0 else \"blue\" for c in coef[interesting_coefficients]]\n",
    "    plt.bar(np.arange(2 * n_top_features), coef[interesting_coefficients], color=colors)\n",
    "    feature_names = np.array(feature_names)\n",
    "    plt.xticks(np.arange(1, 1 + 2 * n_top_features), feature_names[interesting_coefficients], rotation=60, ha=\"right\");\n",
    "\n",
    "visualize_coefficients(logit_pipe['lr_logit'], range(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test, logit_pipe.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.97134309e-03 9.96028657e-01]\n",
      " [5.30564660e-06 9.99994694e-01]\n",
      " [1.71433978e-11 1.00000000e+00]\n",
      " ...\n",
      " [1.58095759e-13 1.00000000e+00]\n",
      " [1.00000000e+00 6.96101408e-13]\n",
      " [9.99999776e-01 2.24255585e-07]] 2000\n"
     ]
    }
   ],
   "source": [
    "test_target = logit_pipe.predict_proba(Xtest)\n",
    "print(test_target, test_target[:,1].size)\n",
    "np.savetxt('test-target.csv',test_target[:,1], fmt='%.15f', delimiter='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_target)\n",
    "print(test_target[:,1].size)\n",
    "np.savetxt('test-target.csv',test_target[:,1], fmt='%.15f', delimiter='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "calibrator = CalibratedClassifierCV(clf, cv='prefit')\n",
    "model=calibrator.fit(X_train, y_train)\n",
    "\n",
    "test_target = model.predict_proba(Xtest)\n",
    "print(test_target[:,1].size)\n",
    "np.savetxt('test-target.csv',test_target[:,1], fmt='%.15f', delimiter='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# подгружаем все нужные пакеты\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# для встроенных картинок\n",
    "%pylab inline\n",
    "# чуть покрасивше картинки:\n",
    "#pd.set_option('display.mpl_style', 'default')\n",
    "figsize(12, 9)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#plt.rcParams['figure.figsize'] = 10, 7.5\n",
    "#plt.rcParams['axes.grid'] = True\n",
    "pd.set_option('display.max_columns', None)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['font.family'] = 'Vernada' # Ubuntu\n",
    "\n",
    "plt.rc('text', usetex=False)\n",
    "plt.rc('font', family='serif')\n",
    "plt.rc('font', weight='bold')\n",
    "plt.rc('xtick', labelsize=14) \n",
    "plt.rc('ytick', labelsize=14)\n",
    "\n",
    "# чтобы был русский шрифт\n",
    "from matplotlib import rc\n",
    " \n",
    "font = {'family': 'Vernada', #Droid Sans\n",
    "        'weight': 'normal'}\n",
    "rc('font', **font)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "class DjStacking(BaseEstimator, ClassifierMixin):  \n",
    "    \"\"\"Стэкинг моделей scikit-learn\"\"\"\n",
    "\n",
    "    def __init__(self, models, ens_model):\n",
    "        \"\"\"\n",
    "        Инициализация\n",
    "        models - базовые модели для стекинга\n",
    "        ens_model - мета-модель\n",
    "        \"\"\"\n",
    "        self.models = models\n",
    "        self.ens_model = ens_model\n",
    "        self.n = len(models)\n",
    "        self.valid = None\n",
    "        \n",
    "    def fit(self, X, y=None, p=0.25, cv=3, err=0.001, random_state=None):\n",
    "        \"\"\"\n",
    "        Обучение стекинга\n",
    "        p - в каком отношении делить на обучение / тест\n",
    "            если p = 0 - используем всё обучение!\n",
    "        cv  (при p=0) - сколько фолдов использовать\n",
    "        err (при p=0) - величина случайной добавки к метапризнакам\n",
    "        random_state - инициализация генератора\n",
    "            \n",
    "        \"\"\"\n",
    "        if (p > 0): # делим на обучение и тест\n",
    "            # разбиение на обучение моделей и метамодели\n",
    "            train, valid, y_train, y_valid = train_test_split(X, y, test_size=p, random_state=random_state)\n",
    "            \n",
    "            # заполнение матрицы для обучения метамодели\n",
    "            self.valid = np.zeros((valid.shape[0], self.n))\n",
    "            for t, clf in enumerate(self.models):\n",
    "                clf.fit(train, y_train)\n",
    "                self.valid[:, t] = clf.predict(valid)\n",
    "                \n",
    "            # обучение метамодели\n",
    "            self.ens_model.fit(self.valid, y_valid)\n",
    "            \n",
    "        else: # используем всё обучение\n",
    "            \n",
    "            # для регуляризации - берём случайные добавки\n",
    "            self.valid = err*np.random.randn(X.shape[0], self.n)\n",
    "            \n",
    "            for t, clf in enumerate(self.models):\n",
    "                # это oob-ответы алгоритмов\n",
    "                self.valid[:, t] += cross_val_predict(clf, X, y, cv=cv, n_jobs=-1, method='predict')\n",
    "                # но сам алгоритм надо настроить\n",
    "                clf.fit(X, y)\n",
    "            \n",
    "            # обучение метамодели\n",
    "            self.ens_model.fit(self.valid, y)  \n",
    "            \n",
    "\n",
    "        return self\n",
    "    \n",
    "\n",
    "\n",
    "    def predict(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Работа стэкинга\n",
    "        \"\"\"\n",
    "        # заполение матрицы для мета-классификатора\n",
    "        X_meta = np.zeros((X.shape[0], self.n))\n",
    "        \n",
    "        for t, clf in enumerate(self.models):\n",
    "            X_meta[:, t] = clf.predict(X)\n",
    "        \n",
    "        a = self.ens_model.predict(X_meta)\n",
    "        \n",
    "        return (a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
